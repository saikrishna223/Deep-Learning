{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=r\"C:\\Users\\DELLPC\\Desktop\\MACHINE_LEARNING\\ML_Projects\\New folder\\Deep Learning\\Cats_Dogs_Prediction\\dataset\\test_set\"\n",
    "train_dir=r\"C:\\Users\\DELLPC\\Desktop\\MACHINE_LEARNING\\ML_Projects\\New folder\\Deep Learning\\Cats_Dogs_Prediction\\dataset\\training_set\"\n",
    "\n",
    "train_dir_cats = train_dir + '/cats'\n",
    "train_dir_dogs = train_dir + '/dogs'\n",
    "test_dir_cats = test_dir + '/cats'\n",
    "test_dir_dogs = test_dir + '/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cats training images -  4001\n",
      "number of dogs training images -  4001\n",
      "number of cats testing images -  1001\n",
      "number of dogs testing images -  1001\n"
     ]
    }
   ],
   "source": [
    "print('number of cats training images - ',len(os.listdir(train_dir_cats)))\n",
    "print('number of dogs training images - ',len(os.listdir(train_dir_dogs)))\n",
    "print('number of cats testing images - ',len(os.listdir(test_dir_cats)))\n",
    "print('number of dogs testing images - ',len(os.listdir(test_dir_dogs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the RGB images into array of numbers by ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_generator = ImageDataGenerator(rescale = 1.0/255.0, zoom_range = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "training_data = data_generator.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (64, 64),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'binary')\n",
    "testing_data = data_generator.flow_from_directory(directory = test_dir,\n",
    "                                                  target_size = (64, 64),\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = training_data.image_shape))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(126, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout( 0.15))\n",
    "model.add(Dense( 64, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units = len(set(training_data.classes)), activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 126)       72702     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 126)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 126)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                145184    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 239,520\n",
      "Trainable params: 239,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 67s 667ms/step - loss: 0.6940 - accuracy: 0.5022 - val_loss: 0.6930 - val_accuracy: 0.5135\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 69s 688ms/step - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6933 - val_accuracy: 0.4981\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 74s 736ms/step - loss: 0.6915 - accuracy: 0.5138 - val_loss: 0.6877 - val_accuracy: 0.5057\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 73s 728ms/step - loss: 0.6779 - accuracy: 0.5763 - val_loss: 0.6522 - val_accuracy: 0.6457\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 73s 727ms/step - loss: 0.6678 - accuracy: 0.5884 - val_loss: 0.6789 - val_accuracy: 0.5493\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 75s 745ms/step - loss: 0.6511 - accuracy: 0.6247 - val_loss: 0.6754 - val_accuracy: 0.6011\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.6290 - accuracy: 0.6441 - val_loss: 0.6054 - val_accuracy: 0.6888\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 76s 757ms/step - loss: 0.6200 - accuracy: 0.6597 - val_loss: 0.5813 - val_accuracy: 0.7085\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.5914 - accuracy: 0.6881 - val_loss: 0.5850 - val_accuracy: 0.6922\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 79s 790ms/step - loss: 0.5768 - accuracy: 0.6994 - val_loss: 0.5781 - val_accuracy: 0.6997\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.5688 - accuracy: 0.7116 - val_loss: 0.5357 - val_accuracy: 0.7356\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.5604 - accuracy: 0.7100 - val_loss: 0.5701 - val_accuracy: 0.7063\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 76s 761ms/step - loss: 0.5564 - accuracy: 0.7188 - val_loss: 0.5292 - val_accuracy: 0.7378\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 77s 771ms/step - loss: 0.5489 - accuracy: 0.7250 - val_loss: 0.5893 - val_accuracy: 0.6853\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 76s 762ms/step - loss: 0.5412 - accuracy: 0.7297 - val_loss: 0.5231 - val_accuracy: 0.7399\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.5309 - accuracy: 0.7422 - val_loss: 0.5367 - val_accuracy: 0.7211\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.5368 - accuracy: 0.7203 - val_loss: 0.5489 - val_accuracy: 0.7305\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 77s 766ms/step - loss: 0.5155 - accuracy: 0.7431 - val_loss: 0.5150 - val_accuracy: 0.7566\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 78s 785ms/step - loss: 0.4865 - accuracy: 0.7631 - val_loss: 0.4989 - val_accuracy: 0.7566\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 76s 764ms/step - loss: 0.5024 - accuracy: 0.7541 - val_loss: 0.4916 - val_accuracy: 0.7560\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.4755 - accuracy: 0.7697 - val_loss: 0.4696 - val_accuracy: 0.7792\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 75s 753ms/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4989 - val_accuracy: 0.7519\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 76s 762ms/step - loss: 0.4756 - accuracy: 0.7781 - val_loss: 0.5101 - val_accuracy: 0.7487\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 0.4420 - accuracy: 0.7887 - val_loss: 0.4595 - val_accuracy: 0.7874\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 76s 762ms/step - loss: 0.4619 - accuracy: 0.7869 - val_loss: 0.4850 - val_accuracy: 0.7622\n"
     ]
    }
   ],
   "source": [
    "fitted_model = model.fit_generator(training_data,\n",
    "                        steps_per_epoch = 100,\n",
    "                        epochs = 25,\n",
    "                        validation_data = testing_data,\n",
    "                        validation_steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting accuracy and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc58ffa4c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = fitted_model.history['accuracy']\n",
    "plt.plot(range(len(accuracy)), accuracy, 'bo', label = 'accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_image(image_directory):\n",
    "    test_image = image.load_img(image_directory, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(x = test_image)\n",
    "    print(result)\n",
    "    if result[0][0]  == 1:\n",
    "        prediction = 'Cat'\n",
    "    else:\n",
    "        prediction = 'Dog'\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]]\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "print(testing_image(test_dir + '/cats/cat.4007.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "print(testing_image(test_dir + '/dogs/dog.4076.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
